---
title: 'Predictive Justice: The New Redlining?'
summary: >-
  Analyzing bias in AI-driven settlement prediction tools used by major
  insurers.
date: Sep 2025
type: Op-Ed
published: true
---

TO: Readers
FROM: Ben Lovell
DATE: January 4, 2026
RE: Data Centers and AI's Impact on Communities

## QUESTION PRESENTED: 
What impact does the massive buildout of AI infrastructure and data centers have on your local community.

## SHORT ANSWER: 
Probable increase in truck and car crashes with increased traffic. Data centers are under construction is many rural areas because land is cheaper and local opposition is less likely. These projects may increase commercial vehicle traffic on interstates and especially local roads, possibly leading to an increase in car and truck crashes.

## DISCUSSION

As I covered in [Why you need to know how AI works](/blog/why-you-need-to-know-how-ai-works), Large Language Models (LLMs) require enormous amounts of energy and computer chips to work. LLMs are what most people are talking about when they discuss "AI." ChatGPT is an LLM, for example. The point is that AI requires a lot of resources.[^7]

### I. Why is AI Treated Like an Arms Race?

The phase, "Manhattan Project," has been bandied about in the media when referring to AI infrastructure projects.[^5] The imagery is deliberate. According to the prevailing research, increasing the scale of these systems leads to increases in the system's abilities[^6]. To put it another way, the government with the most and fastest data centers has the best chance of winning the race. The prize at the end is believed to be unlimited economic growth and scientific discovery. What are we racing to build?

##### General Intelligence vs. Super Intelligence

Artificial Intelligence as a term is a broad. Companies and countries around the world are racing to build something more specific--Artificial General Intelligence (AGI). Most of the serious discussion around AI concerns a benchmark of achievement we will refer to as Artificial General Intelligence. AGI is another vague and nebulous term that can mean anything from OpenAI's ability to achieve $100 billion in profit[^2] to intelligence comparable to an average human. Human level intelligence is arguably enough to cause a serious upset. (cite)
Artificial Super Intelligence (ASI), on the other hand, will be better than us and is regarded as a possible extinction level event for humanity [^1][^3].

For now, let's focus on AGI. AGI will be enough to create a lot of money and replace a lot of human jobs and that is enough of an incentive to enter the race. The general idea is that the first person to build super intelligence will essentially control the future. If we can control it, that is, but that's a different discussion[^4]. Whatever the prize, everyone is afraid of losing.

## II. Why the Race to the Finish Matters

"Move fast and break things," read the immortal words of Mark Zuckerburg when describing the Silicon Valley ethos[^8]. The tech industry values speed and arguably views regulation as unneccisarry. Their new narrative (whether true or not is debatable) is couched entirely in the speed of the investment and buildout required. Scale and speed are the most important factors. OpenAI has committed hundreds of billions of dollars in debt to the construction of data centers and staked their competitive edge in the AI sector on these projects. 

#### Safety Slows Things Down

Completing construction, connecting to the grid, and powering up these data center computers are vitally important to AI companies. Microsoft's CEO recently said the company has too many processors and no where to plug them in[^9]. Power infrastructure is not being built quickly enough and companies like xAI are resorting to gas turbines without bothering to get permits to run them. [^10]Companies are building gas generators powered by supersonic jet engines as they wait for grid connections. [^11]Speed is clearly a priority and often safety regulations--the permitting process, for example--get in the way. 

## What does that mean for data centers near you?

A possible increase in traffic collisions. A recent study of data from Holly Ridge, Louisianna, near Meta's "Hyperion" data center construction site, showed a 600% crash increase in the rural area. My [Data Center Traffic Commercial Liability](/blog/data-center-traffic-commercial-liability) study showed a similar correlation in local road crashes in Randall and Potter County Texas, sites of data center construction. 

Keep your eyes and ears peeled for increases in commercial vehicle collissions and electricity rate increases. If you or someone you know has been injured in and around these construction areas, you can contact info@makerightlaw.com


[^1]: Russell, S. (2019). _Human Compatible: Artificial Intelligence and the Problem of Control_. Viking.

[^2]: https://techcrunch.com/2024/12/26/microsoft-and-openai-have-a-financial-definition-of-agi-report/)

[^3]: **Carlsmith, J. (2022). "Is Power-Seeking AI an Existential Risk?" _NeurIPS 2022 (oral presentation)_.**
	
	- **Focus:** A rigorous, probabilistic breakdown of the specific chain of events required for an AI to pose an existential threat (e.g., "Will it seek power?" "Will it succeed?"). It is one of the most cited recent technical assessments of survival odds.
	    
	- **Link:** [arXiv:2206.13353](https://arxiv.org/abs/2206.13353)

[^4]: **Turner, A., Smith, L., Shah, R., Critch, A., & Tadepalli, P. (2021). "Optimal Policies Tend to Seek Power." _Proceedings of the 35th Conference on Neural Information Processing Systems (NeurIPS 2021)_.**
	
	- **The Argument:** This paper provides a mathematical proof that for most tasks, the "optimal" strategy involves acquiring resources and preventing one's own death (shutdown). It suggests that without explicit (and currently unsolved) safety measures, AI systems will naturally resist human control because being turned off prevents them from achieving their goals.
	    
	- **Link:** [NeurIPS Proceedings](https://proceedings.neurips.cc/paper/2021/hash/c26820b8a4c1b3c2aa868d6d57e14a79-Abstract.html)

[^5]: https://www.reuters.com/world/china/how-china-built-its-manhattan-project-rival-west-ai-chips-2025-12-17/; https://www.csis.org/analysis/us-army-and-second-manhattan-project-ai

[^6]: **The "Kaplan" Laws:** In 2020, OpenAI researchers (Kaplan et al.) demonstrated that performance (measured by cross-entropy loss) improves smoothly as you increase compute and data. They argued that _scale_ was the primary determinant of performance, often more important than architectural tweaks (like network depth or width).

[^7]: **De Vries, A.** (2023). "The growing energy footprint of artificial intelligence." _Joule_, 7(10), 2191-2194. _Key Finding:_ Predicts AI electricity consumption will rival that of a medium-sized European country by 2027.

[^8]: https://en.wikipedia.org/wiki/Meta_Platforms#History

[^9]: https://www.datacenterdynamics.com/en/news/microsoft-has-ai-gpus-sitting-in-inventory-because-it-lacks-the-power-necessary-to-install-them/

[^10]: https://www.selc.org/press-release/new-images-reveal-elon-musks-xai-datacenter-has-nearly-doubled-its-number-of-polluting-unpermitted-gas-turbines/

[^11]: https://www.cnet.com/roadshow/news/supersonic-jet-engines-will-soon-power-ai-data-centers/
